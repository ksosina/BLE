---
title: "Baltimore Life Expectancy"
author: "Kayode Sosina"
date: "September 12, 2016"
output: html_document
references:
- id: mantel
  title: "The Mantel Test versus Pearson's Correlation Analysis: Assessment of the Differences for Biological and Environmental Studies"
  author:
  - family: Dutilleul
    given: Pierre  
  - family: Stockwell 
    given: Jason 
  - family: Frigon
    given: Dominic
  - family: Legendre
    given: Pierre
  container-title: "Journal of Agricultural, Biological, and Environmental Statistics"
  volume: 5
  URL: 'http://www.jstor.org/stable/1400528'
  publisher: "International Biometric Society"
  page: 131-150
  type: article-journal
  issued:
    year: 2000
    month: 6
- id: moran
  title: "Notes on Continuous Stochastic Phenomena"
  author:
  - family: Moran
    given: "Patrick Alfred Pierce"
  container-title: "Biometrika"
  volume: 37
  URL: 'http://www.jstor.org/stable/2332142'
  publisher: " Oxford University Press on behalf of Biometrika Trust"
  page: 17-23
  type: article-journal
  issued:
    year: 1950
    month: 6
- id: mantel1
  title: "The Detection of Disease Clustering and a Generalized Regression Approach"
  author:
  - family: Mantel
    given: "Nathan"
  container-title: "American Association for Cancer Research."
  type: article-journal
  issued:
    year: 1966
    month: 9
- id: fother
  title: "Geographically Weighted Regression: The Analysis of Spatially Varying Relationships"
  author:
  - family: Fotheringham
    given: "A. Stewart"
  - family: Brunsdon
    given: "Chris"
  - family: Charlton
    given: "Martin"
  container-title: " Wiley"
  type: Book
  issued:
    year: 2002
- id: who
  title: "An overarching health indicator for the Post-2015 Development Agenda"
  URL: 'http://www.who.int/healthinfo/indicators/hsi_indicators_SDG_TechnicalMeeting_December2015_BackgroundPaper.pdf'
  type: Article
  issued:
    year: 2014
- id: hdi
  title: "An overarching health indicator for the Post-2015 Development Agenda"
  URL: 'http://hdr.undp.org/en/content/human-development-index-hdi'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Introduction
-------------------

Life expectancy is a measure of how long an individual is expected to live on average and is commonly used in designing policy or even as a social indicator to evaluate the quality of life for any given region [see @who; also @hdi].

The goal of this project is to develop a model for predicting life expectancy in Baltimore down to single block resolution with estimates of uncertainty. The hope is that with this new information we would be able to better examine what factors contribute to the life expectancy for any given block in any given neighborhood in Baltimore city and so aid decision making when policy changes are being implemented. 

We have data gotten from the city of Baltimore which gives estimates of life expectancy at the Community statistical area (CSA) level. This was done since the boundaries, and the names of the 270+ neighborhoods in Baltimore may change over time. Thus the CSA provides a consistent way to characterize a particular region of the city. Each CSA is made up of several neighborhoods and these neighborhoods may belong to more than CSA. I.e., the boundaries of a CSA may go through a neighborhood.

Since our outcome, life expectancy, is gotten at an aggregate level. This project aims to provide a street block prediction of the expected life expectancy using statistical downscaling methods.

```{r housekeeping, include=FALSE, message=FALSE, eval=T}
source(file = file.path("..", "R code", "housekeeping.R"))

```

Data
------------------

We have data from [Baltimore city website](https://data.baltimorecity.gov), [Baltimore Neighborhood Indicators Alliance BNIA-JF](http://bniajfi.org), [Maryland department of planning](http://www.mdp.state.md.us/), and from the [Census Bureau](http://www.census.gov). The data consists of information about life expectancy estimates for each neighbourhood, along with crime, economic development and education informmation, all over a 5 year period (2010-2014). I also have street level, and [block group](https://www.census.gov/geo/reference/gtc/gtc_bg.html) level data. 

```{r data_download, include=FALSE, message=FALSE}

source(file = file.path("..", "R code", "Code_to_download_all_the_data_files.R"))

```

The data fall in three general categories.

  1. Street level 
  2. [Block group](https://www.census.gov/geo/reference/gtc/gtc_bg.html) level 
  3. [Community statistical area level (CSA)](http://bniajfi.org/faqs/)

###Data Cleaning and interpolation
The following table gives some of the variables used in the model fitting process, which level we originally got the data at and assumptions we made to get it at a street block level

| Variables | Name | Level | Cleaning steps |
|:----------:|:-----------:|:-----------:|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| propfemhh | Proportion of households headed by a female with related children under 18 years | Block group | Since the data was at a block group level and we were interested in getting street block level data, we used [Kriging](https://en.wikipedia.org/wiki/Kriging) to [interpolate](https://en.wikipedia.org/wiki/Interpolation) data at new locations (street block locations) using the information from the block group level. The locations for the street blocks were ascertained as the median longitude and latitude of all streets that made up the street block. One of the assumptions made here was that the distribution of the variable (propfemhh) was smooth in the sense that street blocks with such households will tend to be similar. |
| propkids_withinsurance | The proportion of individuals less than 18 years who have health insurance for a given block group | Block group | Here we used the block group value as the value for each street block in that block group. The assumption here was that block groups would tend to be quite homogenous with regard to this variable. |
| racdiv | Racial diversity as calculated per block group | Block group | This variable was not given but was estimated from the block group data on race. Its estimation proceeds as follows calculate the percent of each race, square the percent for each group, sum the squares, subtract the sum from 1.00. Eight groups were used for the index: White, not Hispanic; Black or African American; American Indian and Alaska Native (AIAN); Asian; Native Hawaiian and Other Pacific Islander (NHOPI); two or more races, not Hispanic; some other race, not Hispanic; Hispanic or Latino. This method is based on that used by the census bureau. More information can be found [here](http://www.census.gov/population/cen2000/atlas/censr01-104.pdf). We decided not to interpolate these values for the street blocks but instead used the values from block groups that they belonged to. This was done due to the unique structure of neighborhoods in Baltimore city.  |
| propbelow | Proportion of individuals within a block group that lives below the poverty line | Block group | To get the data at the street block level we interpolated values from the block group level. The assumption used here is that the further into a particular neighborhood you go, the more representative each block is of the aggregate level data for this variable. |
| mhhi | Median household income | Block group | We interpolated the values for the street blocks from the block group level data using Kriging. Again this is based on the assumption that the further into a particular neighborhood you go, the more representative each block is of the aggregate level data for this variable. |
| totalincidents  | # of crime incidents per street | Street | We aggregated this to get the number of crimes committed per street block |
| prop.vacant | Proportion of vacant homes | Street  | We divided the number of vacant homes per street block by the total number of homes in that street block.  |

The rest of the variables used in the final model includes: Percent of 9th-12th Grade Students that are Chronically Absent (abshs); Percentage of Students Suspended or Expelled During School Year (susp); Liquor Outlet density per 1,000 Residents (liquor); Percent of Residences Heated by Utility Gas (heatgas); Percent of Residences Heated by Electricity (elheat); Walk Score (wlksc); and Number of Narcotics Calls for Service per 1,000 Residents(narc). Note that all the variables mentioned above were observed at the CSA level. Furthermore, I did not do any interpolation for these variables at the street block level as I felt that the assumptions inherent in the process would be untenable.

## Descriptives

Since the goal of this analysis is to predict life expectancy at the street block level and since the block information conatined in my dataset does not 
Since some of the data files have information on neighbourhood blocks, I plotted the Neighbourhood information as defined or delineated by the block level data gotten from the [Baltimore city website](https://data.baltimorecity.gov) and then overlayed the neighbourhood data gotten from the [Maryland department of planning](http://www.mdp.state.md.us/). Futhermore, using information from the [Baltimore gisdata website](http://gisdata.baltimorecity.gov) I was able to obtain what "block" was actually defined as. All of this points to the possiblity of using blocks from our dataset as street blocks.

```{r Plots, echo=FALSE, message=FALSE, cache.lazy=TRUE, eval=FALSE}
# print(getwd())
setwd(file.path("..", "Data"))
# print(shape_dirs)

# load up area shape file:

# my_shape_files <- list.files(file.path(".","wip","arts"), pattern = ".shp")
# 
# area <- readShapePoly(file.path(".","wip", "arts",my_shape_files ))
# 
# # library(RColorBrewer)
# 
# 
# # library(ggmap)
# # get_map(location = 'Baltimore', zoom = 12)
# map <- get_map("Baltimore City", 
#                maptype = "terrain",
#                zoom = 12)
# # mapImage <- get_map(location = c(lon = -118, lat = 37.5),
# #   color = "color",
# #   source = "osm",
# #   # maptype = "terrain",
# #   zoom = 6)
# area.points <- broom(area)
# length(unique(area.points$id))
# 
# # colors <- brewer.pal(9, "RdPu")
# 
# ggmap(map) +
#   geom_polygon(aes(x = long,
#                    y = lat,
#                    group = group),
#                data = area.points,
#                fill = area.points$group,
#                alpha = 0.5) +
#   labs(title = "Neighbourhoods as defined by Blocks",
#        x = "Longitude",
#        y = "Latitude")



data <- read_csv(file.path("raw_data", "property.csv"))
subset(data, select = c("Block", "Neighborhood", "Location")) -> data
data <- na.omit(data)
new_loc <-  sapply(data$Location, function(x) {
  y <- substr(x, start = 2, stop = nchar(x) - 1)
  strsplit(y, ", ")[[1]]
}
)
new_loc <- t(new_loc)
data <- data.frame(data[,c(1,2)], lat = as.numeric(new_loc[,1]), lon = as.numeric(new_loc[,2]))

dat <- data.frame(Neighborhood = sort(unique(data$Neighborhood)),
                  lon = tapply(data$lon, data$Neighborhood, median),
                  lat =tapply(data$lat, data$Neighborhood, median), stringsAsFactors=FALSE)

##Choose length of character the name neighbourhood has to have to be displayed
n.name <- 7
dat[nchar(dat$Neighborhood) <= n.name,] -> dat1
map <- get_map(location = "Baltimore City", zoom = 12, maptype = "roadmap" )
p <- ggmap(map)
p + geom_point(data=data,aes(x = lon, y = lat, colour = factor(data$Neighborhood):factor(data$Block) )) +
  geom_text(data=dat1,
            aes(label = as.factor(dat1$Neighborhood)), 
            colour="Black",size=2,hjust="center", 
            vjust="center") +
  labs(title = "Neighbourhoods as defined by Blocks Using just Block level data",
       x = "Longitude",
       y = "Latitude") +
  theme(legend.position = "none") 

gor <- readOGR(file.path("wip", "nhood"), "nhood_2010")
gor <- spTransform(gor, CRS("+proj=longlat +datum=WGS84"))
gor <- tidy(gor)

p + 
  geom_point(data=data,aes(x = lon, y = lat, colour = as.factor(data$Neighborhood) ))  +
  geom_text(data = dat1, aes(label = as.factor(dat1$Neighborhood)), 
            colour="Black",size=2,hjust="center", 
            vjust="center") +
  geom_polygon(data=gor, aes(x=long, y=lat, group=group), color="red", alpha=0) +
  # geom_map(map=gor, data=gor, aes(map_id=id, x=long, y=lat, group=group), color="red", alpha=0) +
  coord_quickmap() +
  labs(title = "The fit of Block info on block data in Baltimore City",
       x = "Longitude",
       y = "Latitude") +
  theme(legend.position = "none") 


##    The fit of Block info on Neighbourhood data in Baltimore City
gor <- readOGR(file.path("wip", "blk2010"), "blk2010")
gor <- spTransform(gor, CRS("+proj=longlat +datum=WGS84"))
gor <- tidy(gor)


p + 
  # geom_point(data=dat1,aes(x = lon, y = lat, colour = as.factor(dat1$Neighborhood),fill = as.factor(dat1$Neighborhood) )) +
  geom_text(data = dat1, aes(label = as.factor(dat1$Neighborhood)), 
            colour="Black",size=2,hjust="center", 
            vjust="center") +
  geom_polygon(data=gor, aes(x=long, y=lat, group=group, fill = group), color="red", alpha=0) +
  # geom_map(map=gor, data=gor, aes(map_id=id, x=long, y=lat, group=group), color="red", alpha=0) +
  coord_map() +
  labs(title = "Blocks in Baltimore City",
       x = "Longitude",
       y = "Latitude") +
  theme(legend.position = "none") 


p + 
  geom_point(data=data,aes(x = lon, y = lat, colour = as.factor(data$Neighborhood) ))  +
  geom_text(data = dat1, aes(label = as.factor(dat1$Neighborhood)), 
            colour="Black",size=2,hjust="center", 
            vjust="center") +
  geom_polygon(data=gor, aes(x=long, y=lat, group=group), color="red", alpha=0) +
  # geom_map(map=gor, data=gor, aes(map_id=id, x=long, y=lat, group=group), color="red", alpha=0) +
  coord_quickmap() +
  labs(title = "The fit of Block info on block data in Baltimore City",
       x = "Longitude",
       y = "Latitude") +
  theme(legend.position = "none") 




# re <- c("No neigbourhoods_data" = dim(dat)[1], "No neigbourhoods_shapefile" = length(unique(gor$group)))
# print(re)

# plot(pressure)


# p + geom_point(data=data,aes(x = lon, y = lat, colour = as.factor(data$Block))) +
#   labs(title = "Neighbourhoods as defined by Blocks",
#        x = "Longitude",
#        y = "Latitude") +
#   theme(legend.position = "none") 



setwd(file.path(".."))
```

<!-- ![Neighbourhoods as defined by blocks using just block level data](../Plots/n_block_block.png) ![The fit of neighbourhood info on block data in Baltimore City](../Plots/block_block.png) ![Blocks in Baltimore City](../Plots/block_n.png)   -->

![](../Plots/block_b.png) 

For more plots examining the fits please visit [my github repo](https://github.com/ksosina/BLE/tree/master/Plots)

```{r proof, echo=FALSE, message=FALSE,warning=FALSE}
real.prop <- read_csv(file.path("..","Data","raw_data", "real_property.csv.gz"))
random_block <- sample(real.prop$BLOCKPLAT,1)
if(!file.exists(file.path("..", "Plots", "random_block.pdf")))
{
  download(random_block, destfile = file.path("..", "Plots", "random_block.pdf"), mode = "wb")
}
# print(getwd())
# file.show(file.path("..", "Plots", "random_block.pdf"))
if(!file.exists(file.path("..", "Plots", "random_block.png")))
{
  im.convert(file.path("..", "Plots", "random_block.pdf"), output = file.path("..", "Plots", "random_block.png"))
}

```

All of this indicate a good fit. I also used gis data from the [baltimore city website](http://gisdata.baltimorecity.gov/) and I found that each block was defined as a street block.[An example of a cityblock pulled from dataset](../Plots/random_block.png)

##Analysis
###Checking for Spatial correlation

Since we have spatial data I ran the both Mantel test[c.f @mantel1] and Moran's I [c.f @moran] to examine if spatial autocorrelation exists in this dataset. Please note that while both test measure spatial autocorrelation, they refer to quite different concepts.

Mantel's test[@mantel1; @mantel] gives correlation between different variables due to their spatial location, that is Mantel's test judges whether closeness in one set of variables is related to closeness in another set of variable. Relating this to our datasetwe can use it to see if samples that are close in terms of their geographic location values are also close in terms of life expectancy values. I.e test if the distance matrix based on life expectancy values is correlated with the distance matrix based on spatial location for the CSA's

```{r Mantel, echo=FALSE, cache=T, message=FALSE, warning=F}
setwd(file.path("..", "Data"))
# setwd(file.path("Data"))

#### ID which neighborhoods fall into a CSA

##Load data from real properties that contains block info
data <- readr::read_csv(file.path("raw_data", "property.csv"))
subset(data, select = c("Block", "Neighborhood", "Location")) -> data

data <- na.omit(data)

new_loc <-  sapply(data$Location, function(x) {
  y <- substr(x, start = 2, stop = nchar(x) - 1)
  strsplit(y, ", ")[[1]]
}
)
new_loc <- t(new_loc)
data <- data.frame(data[,c(1,2)], lon = as.numeric(new_loc[,2]), lat = as.numeric(new_loc[,1]))
dat1 <- data

# dat <- data.frame(Neighborhood = sort(unique(data$Neighborhood)),
#                   lon = data$lon,
#                   lat =data$lat, stringsAsFactors=FALSE)

#Step 1
### Check if Lng and Lat fall inside polygons from ESRI Shape file for Child and wellbeing (this has the outcome)
dat.le <-  rgdal::readOGR(file.path("wip", "health"), "health", verbose = F)
csa <- as.character(dat.le$CSA2010)
dat.le <- sp::spTransform(dat.le, sp::CRS("+proj=longlat +datum=WGS84")) #SpatialPolygonsDataFrame


# Assignment modified according
sp::coordinates(data) <- ~lon + lat #SpatialPointsDataFrame

# Set the projection of the SpatialPointsDataFrame using the projection of the shapefile
sp::proj4string(data) <- sp::proj4string(dat.le)

sp::over(dat.le, data, returnList = T) -> neighbhd_csa #gives which Neighborhood belongs to what CSA

names(neighbhd_csa) <- csa

#Gives a dataframe with cols CSA, Blocks, and Neighborhood so I can match block level info to CSA
neighbhd_csa <- plyr::ldply (neighbhd_csa, data.frame) 
clnames <- names(neighbhd_csa)
clnames[1] <- "CSA"
names(neighbhd_csa) <- clnames

#Got the CSA to NBHD from BNIA site to compare
csa_nsa <- readxl::read_excel(file.path(".", "raw_data", "csa_nsa.xlsx"))

#Caution CSA and neighbourhoods are not in 1-1
with(neighbhd_csa, tapply(CSA, Neighborhood, function(x) length(unique(x)))) -> test.dat

#Get neighbhds where count of CSA = 2 and check
unique(neighbhd_csa[neighbhd_csa$Neighborhood == names(test.dat[test.dat == 2][1]),][,c(1,3)]) -> not.unique
# not.unique


#Step 2
# Now that all that is done, I start merging (on block and neighbhd) to get CSA level, neighborhood level and block level data in one dataset
health <- readr::read_csv(file.path(".", "raw_data", "child_and_fam_wellbeing.csv"))
clnames <- names(health)
clnames[1] <- "CSA"
names(health) <- clnames

# Get variable names
library(dplyr)

gsub("_[[:digit:]]*","",names(health))[-1] -> variables
variables[variables == "mort1"] <- "mort01"
variables <- sapply(variables, function(x){
  substr(x, start = 1, stop = nchar(x) - 2)
})
unname(variables) -> variables
unique(variables) -> var.names


setdiff(names(health), grep(paste0("mort"), names(health), value = T)) ->rm.mort

#Change from short to long

health.long <- lapply(var.names[var.names!= "mort"], function(x){
  #get the columns
  columns <- grep(paste0(x),rm.mort, value = T)
  
  #get the time in years
  time <- sapply(gsub("[^_[:digit:]]","",columns), function(x){
    substr(x, start = nchar(x)-1, stop = nchar(x))
  }
  )
  unname(time) -> time
  
  #Select the columns
  subset(health, select = c("CSA",columns)) -> dat.h
  
  n <- dim(dat.h)[1]

  # print(length(time))
  dat.h <- tidyr::gather(dat.h, variable, value, -CSA)
  dat.h$time <- rep(as.numeric(time), each = n)
  dat.h
  # data.frame(tidyr::gather(dat.h, variable, value, -CSA), time = time)
  # rbind(cbind(tidyr::gather(dat.h, variable, value, -CSA), time))
  
})

plyr::ldply(health.long, data.frame) -> health.long


#get the columns
columns <-  sapply(strsplit(grep(paste0("mort"),names(health), value = T),"_"),function(x) x[1])
unique(columns) -> columns

health.long2 <- lapply(columns, function(x){
  
  #get the time in years
  time <- sapply(strsplit(grep(paste0("^", x, "_"),
                               names(health), value = T),"_"),function(x) x[2])
  time <- as.numeric(time)
  
  #Select the columns
  subset(health, select = c("CSA",
                            grep(paste0("^", x, "_"), names(health), value = T))
         ) -> dat.h
  
  n <- dim(dat.h)[1]
  
  # print(length(time))
  dat.h <- tidyr::gather(dat.h, variable, value, -CSA)
  dat.h$time <- rep(as.numeric(time), each = n)
  dat.h
  # data.frame(tidyr::gather(dat.h, variable, value, -CSA), time = time)
  # rbind(cbind(tidyr::gather(dat.h, variable, value, -CSA), time))
  
})

plyr::ldply(health.long2, data.frame) -> health.long2

health.long <- rbind(health.long, health.long2)

rm(health.long2, columns, rm.mort, var.names, variables, new_loc)

#Merge
health.sub <- subset(health, select = c("CSA", "LifeExp11", 
                                        "LifeExp12", "LifeExp13",
                                        "LifeExp14"))


inner_join(health.sub, neighbhd_csa) %>% #This will have the same number of rows as neighbhd_csa since block neighborhood combinations are unique
  inner_join(dat1) -> merged.h_n         #This will have more rows since dat1 each block in property.csv has multiple streets

# Mantel's Test
#we need CSA to be unique so get the median longitude and latitude per CSA

merged.h_n %>% group_by(CSA) %>%
  summarise(lon.med = median(lon), lat.med = median(lat)) -> mtdata

#note that the number of rows for mtdata is the same as the number of CSA's in our data. Furthermore the number of CSA from BNIA is the same (Baltimore city is not a CSA!!! And so should not be used in the calculations!)

mtdata %>% inner_join(health.sub) -> mtdata

#Testing
# csa.dists <- dist(cbind(mtdata$lon.med, mtdata$lat.med), method = "euclidean")
csa.dists <- geosphere::distm(cbind(mtdata$lon.med, mtdata$lat.med), fun = geosphere::distVincentyEllipsoid)
csa.dists <- as.dist(csa.dists)
le11.dists <- dist(mtdata$LifeExp11, method = "euclidean")

# ade4::mantel.rtest(csa.dists, le11.dists, nrepet = 9999)
# plot(ade4::mantel.rtest(csa.dists, le11.dists, nrepet = 9999))
ade4::mantel.randtest(csa.dists, le11.dists, nrepet = 9999)
plot(ade4::mantel.randtest(csa.dists, le11.dists, nrepet = 9999), main = "Mantel's test")


detach("package:dplyr", unload=TRUE)
# do.call(rbind.data.frame, neighbhd_csa) -> df

setwd(file.path(".."))
```

Based on these results, we can reject the null hypothesis that these two matrices, spatial distance and life expectancy distance (2011), are unrelated with alpha = 0.05.  The observed correlation, r = 0.1271281, suggests that the matrix entries are positively associated. So smaller differences in life expectancy are generally seen among pairs of CSA's that are close to each other than far from each other. Note that since this test is based on random permutations, the same code will always arrive at the same observed correlation but rarely the same p-value. Furthemore, I ran this test for all four years in the datset set and the conclusions are consistent. If you are interested in the correlation values for those years [here is the code](https://github.com/ksosina/BLE/blob/master/R%20code/check_sp_corr.R).

Moran's I[@moran] is useful when one wants to know the correlation of a variable with itself through space. I.e., when one wants to know to which extent the occurrence of an event in an areal unit makes it more likely or unlikely the occurrence of an event in a neighboring areal unit. I.e if life expectancy is low in the north does that mean that we likely to see low life expectancy in the same region? Thus the null is the lack of existence of spatial autocorrelation.
```{r Moran, echo=FALSE, cache=TRUE, message=FALSE, warning=F}

csa.dists <- as.matrix(csa.dists)

csa.dists.inv <- 1/csa.dists #solve(csa.dists)
diag(csa.dists.inv) <- 0

#2011
ape::Moran.I(mtdata$LifeExp11, csa.dists.inv)

```
Based on these results, we can reject the null hypothesis that there is zero spatial autocorrelation present in life expectancy at the 5\% level of significance. For more tests using data from 2011 to 2014 please check [here]((https://github.com/ksosina/BLE/blob/master/R%20code/check_sp_corr.R)).

###Regression Models for spatial data
####Geographically Weighted Regression (GWR)
* The structure of the model does not remain constant over the study area (there are local variations in the parameter estimates)
* To account for this potential spatial heterogeneity we use the GWR model [@fother]
* GWR permits the parameter estimates to vary locally.

#####GWR
This model uses a weighted least squares approach to account for spatial heteorgeniety and is as follows $$Y_i = X\beta_i + \epsilon_i $$ where i is the location and $\beta_i$ is solved using the WLS approach. Thus $$ \beta_i = (X^TW_iX)^{-1}X^TW_iY $$ where $W_i$ is the weight matrix 

####Methods for Downscaling
* Delta method:
Here, after we find the model that fits the date best, using aggregated data. 
    1. We predict what the life expectancy would be after we remove one of the blocks from the aggregated data, call this $$ T_{-b} = E(Y)_{-b} $$ 
    2. Then we find the delta in predicted life expectancy at the CSA level due to the removed block as $$ T_{\delta_b} = T_{full} â€“ T_{-b} $$ Call this delta the change in the mean life expectancy at the CSA level due to that block.
    3. Add the delta to the observed life expectancy at that CSA. Call this the predicted life expectancy due to that block
Note that this inherently assumes that the observed life expectancy at a CSA is the true underlying life expectancy and that all the blocks in the neighborhoods that belong that CSA vary about it.

* Transfer function: Find which aggregated predictors provide the best fit, then use a "transfer function" to map the aggregated variables to the block level and use the value gotten as a predictor to get block level estimates.
 

## Datasets

| Name                                    | Information                                                                                                                                                                                                             | Type      | Data Source                                                                                          | Geographic Scale   | Date        |
|-----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|------------------------------------------------------------------------------------------------------|--------------------|-------------|
| Real Property Taxes                     | Contains information on which streets belong to which block and in what neighbourhood along with their longitude and latitude. Also has information on police district.                                                 | Dataset   | [Baltimore city website](https://data.baltimorecity.gov)                                             | Street Level       | 2016        |
| Real Property                           | Contains the City of Baltimore parcel boundaries, with ownership, address, valuation and other property information. Furthermore, it also contains street block definitions.                                            | Dataset   | [Baltimore gisdata website](http://gisdata.baltimorecity.gov)                                        | Street level       | 2016        |
| Census Block                            | GIS shapefile which has information on census block designation for 2010                                                                                                                                                | Shapefile | [Maryland department of planning](http://planning.maryland.gov/msdc/S5_Map_GIS.Shtml)                | Block level        | 2010        |
| Neighborhoood                           | Polygon feature representing the boundaries of Baltimore City's neighborhoods as of the year 2010                                                                                                                       | Shapefile | [Baltimore city website](https://data.baltimorecity.gov)                                             | Neighborhood level | 2010        |
| Census Demographics for 2010 to 2014    | Contains neighborhood level demographics data                                                                                                                                                                           | Dataset   | [Baltimore Neighborhood Indicators Alliance BNIA-JF](http://bniajfi.org/vital_signs/data_downloads/) | Neighborhood level | 2010 - 2014 |
| Children and Family Health & Well-Being | Has information on life expectancy for 2010 to 2014                                                                                                                                                                     | Dataset   | [Baltimore Neighborhood Indicators Alliance BNIA-JF](http://bniajfi.org/vital_signs/data_downloads/) | Neighborhood level | 2010 - 2014 |
| BNIA Vital Signs Codebook               | Contain information on short variable names and their corresponding full names, along with their sources for each dataset                                                                                               | Dataset   | [Baltimore city website](https://data.baltimorecity.gov)                                             | Neighborhood level | 2016        |
| Housing and Community Development       | Has information on the state of households in Baltimore city, viz;Number of Homes Sold,Percentage of Residential Properties that are Vacant and Abandoned,Percent Residential Properties that do Not Receive Mail, etc. | Dataset   | [Baltimore Neighborhood Indicators Alliance BNIA-JF](http://bniajfi.org/vital_signs/data_downloads/) | Neighborhood level | 2010-2014   |
| BNIA Data linking CSA to Neighborhoods      | Has information on which neighborhoods belong to what CSA. Note that a neighborhood may belong to more than one CSA | Dataset   | [Baltimore Neighborhood Indicators Alliance BNIA-JF](http://bniajfi.org/mapping-resources/) | CSA and Neighborhood level | 2010   |
| Census Bureau    | Has information at the block group level. This includes information on family types, poverty status, the median househoold income  | Dataset   | [ American FactFinder](https://www.census.gov/acs/www/data/data-tables-and-tools/american-factfinder/) | Census tract and Block group level | 2014 |



```{r version info}
devtools::session_info()
```

# References
